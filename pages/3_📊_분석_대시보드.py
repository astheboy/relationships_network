# pages/3_ğŸ“Š_ë¶„ì„_ëŒ€ì‹œë³´ë“œ.py
import streamlit as st
from supabase import Client, PostgrestAPIResponse
import pandas as pd
import json
import plotly.express as px # ì‹œê°í™”ë¥¼ ìœ„í•´ Plotly ì¶”ê°€ (pip install plotly)
import os

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ë¶„ì„ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

# --- Supabase í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° ---
@st.cache_resource
def init_connection():
    url = None
    key = None
    # ... (ì´ì „ê³¼ ë™ì¼) ...
    try:
        url = st.secrets["supabase"]["url"]
        key = st.secrets["supabase"]["key"]
        return create_client(url, key)
    except Exception as e:
        url = os.environ.get("SUPABASE_URL")
        key = os.environ.get("SUPABASE_KEY") # ë˜ëŠ” SUPABASE_ANON_KEY ë“± Renderì— ì„¤ì •í•œ ì´ë¦„
        # if url and key:
        #      st.write("DEBUG: Loaded credentials from environment variables") # ë””ë²„ê¹…ìš©
        # else:
        #      st.write("DEBUG: Environment variables not found either.") # ë””ë²„ê¹…ìš©


    if url and key:
        try:
            return create_client(url, key)
        except Exception as e:
            st.error(f"Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    else:
        # URL ë˜ëŠ” Keyë¥¼ ì–´ë””ì—ì„œë„ ì°¾ì§€ ëª»í•œ ê²½ìš°
        st.error("Supabase ì—°ê²° ì •ë³´(Secrets ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

from supabase import create_client
supabase = init_connection()

# --- ì¸ì¦ í™•ì¸ ---
if not st.session_state.get('logged_in'):
    st.warning("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

if not supabase:
    st.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

teacher_id = st.session_state.get('teacher_id')
teacher_name = st.session_state.get('teacher_name', 'ì„ ìƒë‹˜')

st.title(f"ğŸ“Š {teacher_name}ì˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.write("í•™ê¸‰ê³¼ ì„¤ë¬¸ íšŒì°¨ë¥¼ ì„ íƒí•˜ì—¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.")

# --- í•™ê¸‰ ë° ì„¤ë¬¸ íšŒì°¨ ì„ íƒ ---
st.divider()
col1, col2 = st.columns(2)

selected_class_id = None
selected_survey_id = None
selected_class_name = None
selected_survey_name = None

with col1:
    st.subheader("1. ë¶„ì„ ëŒ€ìƒ í•™ê¸‰ ì„ íƒ")
    try:
        class_response = supabase.table('classes') \
            .select("class_id, class_name") \
            .eq('teacher_id', teacher_id) \
            .order('created_at', desc=False) \
            .execute()

        if class_response.data:
            classes = class_response.data
            class_options = {c['class_name']: c['class_id'] for c in classes}
            class_options_with_prompt = {"-- í•™ê¸‰ ì„ íƒ --": None}
            class_options_with_prompt.update(class_options) # ë§¨ ì•ì— ì„ íƒ ì•ˆë‚´ ì¶”ê°€
            selected_class_name = st.selectbox(
                "ë¶„ì„í•  í•™ê¸‰:",
                options=class_options_with_prompt.keys(),
                key="class_select_analysis"
            )
            selected_class_id = class_options_with_prompt.get(selected_class_name)
        else:
            st.info("ë¨¼ì € 'í•™ê¸‰ ë° í•™ìƒ ê´€ë¦¬' ë©”ë‰´ì—ì„œ í•™ê¸‰ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"í•™ê¸‰ ëª©ë¡ ë¡œë”© ì˜¤ë¥˜: {e}")

with col2:
    st.subheader("2. ë¶„ì„ ëŒ€ìƒ ì„¤ë¬¸ ì„ íƒ")
    if selected_class_id:
        try:
            survey_response = supabase.table('surveys') \
                .select("survey_instance_id, survey_name") \
                .eq('class_id', selected_class_id) \
                .order('created_at', desc=True) \
                .execute()

            if survey_response.data:
                surveys = survey_response.data
                survey_options = {s['survey_name']: s['survey_instance_id'] for s in surveys}
                survey_options_with_prompt = {"-- ì„¤ë¬¸ ì„ íƒ --": None}
                survey_options_with_prompt.update(survey_options)
                selected_survey_name = st.selectbox(
                    f"'{selected_class_name}' í•™ê¸‰ì˜ ì„¤ë¬¸:",
                    options=survey_options_with_prompt.keys(),
                    key="survey_select_analysis"
                )
                selected_survey_id = survey_options_with_prompt.get(selected_survey_name)
            else:
                st.info("ì„ íƒëœ í•™ê¸‰ì— ëŒ€í•œ ì„¤ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ì„¤ë¬¸ ê´€ë¦¬' ë©”ë‰´ì—ì„œ ìƒì„±í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì„¤ë¬¸ ëª©ë¡ ë¡œë”© ì˜¤ë¥˜: {e}")
    else:
        st.info("ë¨¼ì € í•™ê¸‰ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

# --- ë°ì´í„° ë¡œë“œ ë° ë¶„ì„ ---
st.divider()
if selected_class_id and selected_survey_id:
    st.subheader(f"'{selected_class_name}' - '{selected_survey_name}' ë¶„ì„ ê²°ê³¼")

    @st.cache_data(ttl=300) # 5ë¶„ ìºì‹±
    def load_analysis_data(_survey_instance_id):
        try:
            # 1. ì‘ë‹µ ë°ì´í„° ë¡œë“œ (í•™ìƒ ì •ë³´ í¬í•¨)
            response = supabase.table('survey_responses') \
                .select("*, students(student_id, student_name)") \
                .eq('survey_instance_id', _survey_instance_id) \
                .execute()

            if not response.data:
                st.warning("ì„ íƒëœ ì„¤ë¬¸ì— ëŒ€í•œ ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None, None

            responses_df = pd.DataFrame(response.data)

            # 2. í•™ìƒ ì´ë¦„ ë§¤í•‘ ë° 'relation_mapping_data' íŒŒì‹±
            all_students_map = {} # ì „ì²´ í•™ìƒ ID:ì´ë¦„ ë§µ
            parsed_responses = []

            for index, row in responses_df.iterrows():
                student_info = row.get('students') # students(student_id, student_name) ë¶€ë¶„
                if not student_info: continue # í•™ìƒ ì •ë³´ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°

                submitter_id = student_info['student_id']
                submitter_name = student_info['student_name']
                all_students_map[submitter_id] = submitter_name # í•™ìƒ ë§µì— ì¶”ê°€

                # JSON íŒŒì‹±
                relation_data = {}
                try:
                    if row.get('relation_mapping_data'):
                        relation_data = json.loads(row['relation_mapping_data'])
                except json.JSONDecodeError:
                    print(f"Warning: Failed to parse relation_mapping_data for response {row.get('response_id')}")

                # íŒŒì‹±ëœ ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
                parsed_row = row.to_dict()
                parsed_row['submitter_id'] = submitter_id
                parsed_row['submitter_name'] = submitter_name
                parsed_row['parsed_relations'] = relation_data # íŒŒì‹±ëœ dict ì €ì¥
                parsed_responses.append(parsed_row)

            if not parsed_responses:
                 st.warning("ìœ íš¨í•œ ì‘ë‹µ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                 return None, None

            analysis_df = pd.DataFrame(parsed_responses)
            return analysis_df, all_students_map

        except Exception as e:
            st.error(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None

    # ë°ì´í„° ë¡œë“œ ì‹¤í–‰
    analysis_df, students_map = load_analysis_data(selected_survey_id)

    if analysis_df is not None and students_map:
        # --- íƒ­ êµ¬ì„± (ê¸°ë³¸ ë¶„ì„ + AI ë¶„ì„ íƒ­) ---
        tab_list = ["ğŸ“Š ê´€ê³„ ë¶„ì„", "ğŸ’¬ ì„œìˆ í˜• ì‘ë‹µ", "ğŸ“„ ì›ë³¸ ë°ì´í„°", "âœ¨ AI ì‹¬ì¸µ ë¶„ì„"]
        tab1, tab2, tab3, tab4 = st.tabs(tab_list)

        with tab1:
            st.header("ê´€ê³„ ë¶„ì„ (ì¹œë°€ë„ ì ìˆ˜ ê¸°ë°˜)")
            # --- !!! ì—¬ê¸°ì— ê¸°ë³¸ì ì¸ ê´€ê³„ ì ìˆ˜ ë¶„ì„ ë° ì‹œê°í™” ì½”ë“œ !!! ---
            # (ì˜ˆ: í‰ê·  ë°›ì€ ì ìˆ˜ ë§‰ëŒ€ ê·¸ë˜í”„ ë“± ì´ì „ ë‹¨ê³„ì—ì„œ êµ¬í˜„í•œ ë‚´ìš©)
                        # 1. ë°›ì€ ì¹œë°€ë„ ì ìˆ˜ ê³„ì‚°
            received_scores = {} # key: student_id, value: list of scores received
            for student_id in students_map.keys():
                received_scores[student_id] = []

            for index, row in analysis_df.iterrows():
                relations = row.get('parsed_relations', {})
                for target_student_id, relation_info in relations.items():
                    score = relation_info.get('intimacy')
                    if isinstance(score, (int, float)) and target_student_id in received_scores:
                        received_scores[target_student_id].append(score)

            # 2. í‰ê·  ë°›ì€ ì ìˆ˜ ê³„ì‚° ë° ì‹œê°í™”
            avg_received_scores = []
            for student_id, scores in received_scores.items():
                if scores:
                    avg_score = sum(scores) / len(scores)
                    avg_received_scores.append({
                        'student_id': student_id,
                        'student_name': students_map.get(student_id, 'Unknown'),
                        'average_score': avg_score,
                        'received_count': len(scores)
                    })

            if avg_received_scores:
                avg_df = pd.DataFrame(avg_received_scores).sort_values(by='average_score', ascending=False)

                st.subheader("í•™ìƒë³„ í‰ê·  ë°›ì€ ì¹œë°€ë„ ì ìˆ˜")
                fig = px.bar(avg_df, x='student_name', y='average_score',
                             title="í‰ê·  ë°›ì€ ì¹œë°€ë„ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ê¸ì •ì  ê´€ê³„)",
                             labels={'student_name':'í•™ìƒ ì´ë¦„', 'average_score':'í‰ê·  ì ìˆ˜'},
                             hover_data=['received_count'], # ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ë°›ì€ íšŸìˆ˜ í‘œì‹œ
                             color='average_score', # ì ìˆ˜ì— ë”°ë¼ ìƒ‰ìƒ ë³€í™”
                             color_continuous_scale=px.colors.sequential.Viridis) # ìƒ‰ìƒ ìŠ¤ì¼€ì¼
                st.plotly_chart(fig, use_container_width=True)

                # ê°„ë‹¨ ë¶„ì„
                highest = avg_df.iloc[0]
                lowest = avg_df.iloc[-1]
                st.write(f"ğŸŒŸ ê°€ì¥ ë†’ì€ í‰ê·  ì ìˆ˜ë¥¼ ë°›ì€ í•™ìƒ: **{highest['student_name']}** ({highest['average_score']:.1f}ì , {highest['received_count']}íšŒ)")
                st.write(f"ğŸ˜Ÿ ê°€ì¥ ë‚®ì€ í‰ê·  ì ìˆ˜ë¥¼ ë°›ì€ í•™ìƒ: **{lowest['student_name']}** ({lowest['average_score']:.1f}ì , {lowest['received_count']}íšŒ)")
            else:
                st.write("ë°›ì€ ì¹œë°€ë„ ì ìˆ˜ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.write("ê¸°ë³¸ ê´€ê³„ ë¶„ì„ ë‚´ìš© í‘œì‹œ")

        with tab2:
            st.header("ì„œìˆ í˜• ì‘ë‹µ ë³´ê¸°")
            # --- !!! ì—¬ê¸°ì— ì„œìˆ í˜• ì‘ë‹µ DataFrame í‘œì‹œ ì½”ë“œ !!! ---
            text_columns = [
                'submitter_name', 'praise_friend', 'praise_reason', 'difficult_friend',
                'difficult_reason', 'otherclass_friendly_name', 'otherclass_friendly_reason',
                'otherclass_bad_name', 'otherclass_bad_reason', 'concern', 'teacher_message'
            ]
            # analysis_dfì— í•´ë‹¹ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸ í›„ ì„ íƒ
            available_text_columns = [col for col in text_columns if col in analysis_df.columns]
            st.dataframe(analysis_df[available_text_columns], use_container_width=True)
            st.write("ì„œìˆ í˜• ì‘ë‹µ í…Œì´ë¸” í‘œì‹œ")
            # text_columns = [...]
            # st.dataframe(analysis_df[available_text_columns])

        with tab3:
            st.header("ì›ë³¸ ë°ì´í„° ë³´ê¸°")
            # --- !!! ì—¬ê¸°ì— ì „ì²´ ì›ë³¸ DataFrame í‘œì‹œ ì½”ë“œ !!! ---
            st.dataframe(analysis_df, use_container_width=True)
            st.caption("`parsed_relations` ì—´ì—ì„œ ê° í•™ìƒì´ ë‹¤ë¥¸ í•™ìƒë“¤ì—ê²Œ ë§¤ê¸´ ì¹œë°€ë„ ì ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.write("ì›ë³¸ ë°ì´í„° í…Œì´ë¸” í‘œì‹œ")
            # st.dataframe(analysis_df)

        # --- AI ì‹¬ì¸µ ë¶„ì„ íƒ­ (ì¡°ê±´ë¶€ ë‚´ìš© í‘œì‹œ) ---
        with tab4:
            st.header("AI ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (Gemini)")

            # ì„¸ì…˜ì—ì„œ API í‚¤ í™•ì¸
            api_key = st.session_state.get('gemini_api_key')

            if api_key:
                st.success("âœ… Gemini API í‚¤ê°€ í™œì„±í™”ë˜ì–´ AI ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                st.write("AI ë¶„ì„ ê²°ê³¼ë¥¼ ì—¬ê¸°ì— í‘œì‹œí•©ë‹ˆë‹¤. (ì˜ˆ: ì£¼ìš” ê³ ë¯¼ ìš”ì•½, ê´€ê³„ íŒ¨í„´ ë¶„ì„ ë“±)")

                # --- !!! ì—¬ê¸°ì— AI ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ ë° ê²°ê³¼ í‘œì‹œ ë¡œì§ êµ¬í˜„ !!! ---
                # ì˜ˆì‹œ:
                if st.button("í•™ìƒ ê³ ë¯¼ ë‚´ìš© AI ìš”ì•½"):
                    # analysis_df['concern'] ë‚´ìš©ì„ ê°€ì ¸ì™€ì„œ Gemini API í˜¸ì¶œ
                    # ê²°ê³¼ í‘œì‹œ
                    st.info("AI ìš”ì•½ ê¸°ëŠ¥ êµ¬í˜„ ì˜ˆì •")
                    pass

                # ë‹¤ë¥¸ AI ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€...

            else:
                # API í‚¤ê°€ ì—†ì„ ë•Œ ì•ˆë‚´ ë©”ì‹œì§€ ë° ì„¤ì • í˜ì´ì§€ ë§í¬ í‘œì‹œ
                st.warning("âš ï¸ AI ê¸°ë°˜ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                st.markdown("""
                    API í‚¤ë¥¼ ì…ë ¥í•˜ë©´ í•™ìƒë“¤ì˜ ì„œìˆ í˜• ì‘ë‹µì— ëŒ€í•œ ìë™ ìš”ì•½, ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ,
                    ê´€ê³„ íŒ¨í„´ì— ëŒ€í•œ ì‹¬ì¸µì ì¸ í•´ì„ ë“± ì¶”ê°€ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

                    API í‚¤ëŠ” **ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ 'âš™ï¸ ì„¤ì •' ë©”ë‰´**ì—ì„œ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    í‚¤ ë°œê¸‰ì€ [Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                """)
                # ì„¤ì • í˜ì´ì§€ë¡œ ë°”ë¡œ ì´ë™í•˜ëŠ” ë§í¬ (ì„ íƒ ì‚¬í•­)
                st.page_link("pages/4_âš™ï¸_ì„¤ì •.py", label="ì„¤ì • í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ API í‚¤ ì…ë ¥í•˜ê¸°", icon="âš™ï¸")

    else:
        # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ (load_analysis_data í•¨ìˆ˜ ë‚´ì—ì„œ ì´ë¯¸ ê²½ê³ /ì˜¤ë¥˜ í‘œì‹œë¨)
        pass

else:
    st.info("ë¶„ì„í•  í•™ê¸‰ê³¼ ì„¤ë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")